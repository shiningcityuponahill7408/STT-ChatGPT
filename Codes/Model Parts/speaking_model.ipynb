{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*** Speaker diarization and transcription\n",
        "1. Use Whisper model to get transcription and (start, end) pair\n",
        "2. Segment the audio file into pieces according to (start, end) pair that we got from (1)\n",
        "3. Do speaker embedding\n",
        "4. Use {}"
      ],
      "metadata": {
        "id": "tvdc1yFM1mqt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgKtiItW1gTZ",
        "outputId": "1a4f34c6-6243-4cc2-a42b-63bd32631539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U yt-dlp -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O - -q  https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz | xz -qdc| tar -x"
      ],
      "metadata": {
        "id": "h9yO36k_3-mN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 부부 대화\n",
        "!yt-dlp -xv --ffmpeg-location ffmpeg-master-latest-linux64-gpl/bin --audio-format wav  -o marriage_conversation.wav -- https://youtu.be/H0gH8orEidc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW8zSbBO3_vi",
        "outputId": "2ce3108e-d4de-4897-9a92-821083690cab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] Command-line config: ['-xv', '--ffmpeg-location', 'ffmpeg-master-latest-linux64-gpl/bin', '--audio-format', 'wav', '-o', 'marriage_conversation.wav', '--', 'https://youtu.be/H0gH8orEidc']\n",
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out utf-8, error utf-8, screen utf-8\n",
            "[debug] yt-dlp version stable@2023.03.04 [392389b7d] (pip)\n",
            "[debug] Python 3.10.11 (CPython x86_64 64bit) - Linux-5.10.147+-x86_64-with-glibc2.31 (OpenSSL 1.1.1f  31 Mar 2020, glibc 2.31)\n",
            "[debug] exe versions: ffmpeg N-110422-g7b2851b290-20230430 (setts), ffprobe N-110422-g7b2851b290-20230430\n",
            "[debug] Optional libraries: Cryptodome-3.17, brotli-1.0.9, certifi-2022.12.07, mutagen-1.46.0, sqlite3-2.6.0, websockets-11.0.2\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Loaded 1786 extractors\n",
            "[youtube] Extracting URL: https://youtu.be/H0gH8orEidc\n",
            "[youtube] H0gH8orEidc: Downloading webpage\n",
            "[youtube] H0gH8orEidc: Downloading android player API JSON\n",
            "[youtube] H0gH8orEidc: Downloading player 0c487f05\n",
            "[debug] Saving youtube-nsig.0c487f05 to cache\n",
            "[debug] [youtube] Decrypted nsig k2dPFhIdONmtK882h => MbJcHDTFytx8Hw\n",
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, filesize, fs_approx, tbr, vbr, abr, asr, vext, aext, hasaud, id\n",
            "[info] H0gH8orEidc: Downloading 1 format(s): 251\n",
            "[debug] Invoking dashsegments downloader on \"https://rr1---sn-npoe7ne6.googlevideo.com/videoplayback?expire=1683038207&ei=n8tQZOu1DKKnvcAPoIqFoAw&ip=34.124.166.87&id=o-ADG63FWKhkef335_fapfl5FsbhiiOjeuu2kUJu3FS_QH&itag=251&source=youtube&requiressl=yes&mh=Q7&mm=31%2C29&mn=sn-npoe7ne6%2Csn-npoeens7&ms=au%2Crdu&mv=m&mvi=1&pl=21&ctier=SH&spc=qEK7B2hycFcu4W3qbZwCGuUouA6LHCk&vprv=1&svpuc=1&mime=audio%2Fwebm&gir=yes&clen=553145&dur=36.161&lmt=1671093450673261&mt=1683016138&fvip=5&keepalive=yes&fexp=24007246&c=ANDROID&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cctier%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cgir%2Cclen%2Cdur%2Clmt&sig=AOq0QJ8wRgIhAM7VpLPzjcjDU9DANnvtEclvqcQ8IDPei0eclvECXAi9AiEAyVZSnbcYVA7GWVgae_rU4ykftW7iThuzJG31gPs2pKM%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AG3C_xAwRgIhAPZt-gx2WfDI7WXpZ7XOcumAFi6Ontzk0XRsgjBQY87yAiEA-2J_dqJ6gseIm79HFb0WUCi6mKjhrOHeUpd6cKs7-r0%3D\"\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: marriage_conversation.webm\n",
            "\u001b[K[download] 100% of  540.18KiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m9.16MiB/s\u001b[0m\n",
            "[debug] ffmpeg command line: ffmpeg-master-latest-linux64-gpl/bin/ffprobe -show_streams file:marriage_conversation.webm\n",
            "[ExtractAudio] Destination: marriage_conversation.wav\n",
            "[debug] ffmpeg command line: ffmpeg-master-latest-linux64-gpl/bin/ffmpeg -y -loglevel repeat+info -i file:marriage_conversation.webm -vn -movflags +faststart file:marriage_conversation.wav\n",
            "Deleting original file marriage_conversation.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub -q"
      ],
      "metadata": {
        "id": "3MXb9xlW3_sM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall --yes torch torchvision torchaudio \n",
        "! pip3 install torch torchvision torchaudio --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_UzrZYl3_VK",
        "outputId": "bc9da84d-801f-4496-a645-97a4b1f4156e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.0+cu118\n",
            "Uninstalling torch-2.0.0+cu118:\n",
            "  Successfully uninstalled torch-2.0.0+cu118\n",
            "Found existing installation: torchvision 0.15.1+cu118\n",
            "Uninstalling torchvision-0.15.1+cu118:\n",
            "  Successfully uninstalled torchvision-0.15.1+cu118\n",
            "Found existing installation: torchaudio 2.0.1+cu118\n",
            "Uninstalling torchaudio-2.0.1+cu118:\n",
            "  Successfully uninstalled torchaudio-2.0.1+cu118\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git > /dev/null"
      ],
      "metadata": {
        "id": "s9FlID7o4mey"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/RF5/simple-speaker-embedding.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-deWqc56Y_q",
        "outputId": "965697ab-ccfa-42ce-9da9-8b4a4651bf1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simple-speaker-embedding'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 116 (delta 63), reused 70 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (116/116), 1.22 MiB | 4.24 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import wave\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "r5jdiW3e-eKr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"large-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt58mt-q6JbW",
        "outputId": "73a9a226-54a9-4c3d-dce3-c54f27f05408"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:55<00:00, 56.0MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"marriage_conversation.wav\")\n",
        "segments = result[\"segments\"]"
      ],
      "metadata": {
        "id": "nVp2o5iP7SPS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaymJz0r_apE",
        "outputId": "588a0b9a-5d3b-4a20-f580-7fce5866caf5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.4, 'text': ' 그냥 여보가 말을 좀 가끔씩 아직은 노력 많이 하지만 거칠게 할 때가 있어서', 'tokens': [50364, 11208, 8228, 7062, 1453, 39692, 6796, 10583, 30895, 24317, 22729, 2124, 49388, 8358, 23286, 3675, 45398, 1810, 8981, 7765, 1453, 27937, 50734], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 1, 'seek': 0, 'start': 7.4, 'end': 9.040000000000001, 'text': ' 존댓말 쓰잖아요 그래서', 'tokens': [50734, 22116, 1327, 234, 241, 11023, 17373, 13928, 8844, 50816], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 2, 'seek': 0, 'start': 9.040000000000001, 'end': 11.040000000000001, 'text': ' 거칠게 존댓말 하잖아요', 'tokens': [50816, 3675, 45398, 1810, 22116, 1327, 234, 241, 11023, 3369, 13928, 50916], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 3, 'seek': 0, 'start': 11.040000000000001, 'end': 13.040000000000001, 'text': ' 아니', 'tokens': [50916, 5651, 51016], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 4, 'seek': 0, 'start': 13.040000000000001, 'end': 15.040000000000001, 'text': ' 음', 'tokens': [51016, 220, 5654, 51116], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 5, 'seek': 0, 'start': 15.040000000000001, 'end': 17.04, 'text': ' 음', 'tokens': [51116, 15179, 51216], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 6, 'seek': 0, 'start': 17.04, 'end': 19.04, 'text': ' 왜', 'tokens': [51216, 9883, 51316], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 7, 'seek': 0, 'start': 19.04, 'end': 19.84, 'text': ' 뭐가 있어요?', 'tokens': [51316, 39713, 12654, 30, 51356], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 8, 'seek': 0, 'start': 19.84, 'end': 21.84, 'text': ' 힘줄?', 'tokens': [51356, 30326, 23620, 30, 51456], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 9, 'seek': 0, 'start': 21.84, 'end': 23.84, 'text': ' 힘줄인가?', 'tokens': [51456, 30326, 23620, 41755, 30, 51556], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 10, 'seek': 0, 'start': 23.84, 'end': 25.84, 'text': ' 소의 힘줄이지 뭐 뼈가 있겠어요?', 'tokens': [51556, 10614, 2785, 30326, 23620, 25721, 7034, 531, 120, 230, 1453, 2297, 30826, 30, 51656], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 11, 'seek': 0, 'start': 25.84, 'end': 27.84, 'text': ' 뼈도 있지', 'tokens': [51656, 531, 120, 22616, 37693, 51756], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 12, 'seek': 2784, 'start': 28.68, 'end': 30.68, 'text': ' 그 비아냥거리는 말투도 싫어요', 'tokens': [50406, 4296, 10079, 23733, 10408, 4261, 7078, 1098, 7058, 169, 48458, 1838, 33649, 4213, 50506], 'temperature': 0.0, 'avg_logprob': -0.3816612492436948, 'compression_ratio': 0.8846153846153846, 'no_speech_prob': 0.22522757947444916}, {'id': 13, 'seek': 2784, 'start': 32.68, 'end': 34.68, 'text': ' 어떻게 살아요 내랑', 'tokens': [50606, 12952, 46978, 1495, 15139, 9143, 50706], 'temperature': 0.0, 'avg_logprob': -0.3816612492436948, 'compression_ratio': 0.8846153846153846, 'no_speech_prob': 0.22522757947444916}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for count, x in enumerate(segments):\n",
        "  print(x[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMRl_bQH-9XQ",
        "outputId": "6cb930f4-c1d4-4988-dceb-26c07ac599f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 그냥 여보가 말을 좀 가끔씩 아직은 노력 많이 하지만 거칠게 할 때가 있어서\n",
            " 존댓말 쓰잖아요 그래서\n",
            " 거칠게 존댓말 하잖아요\n",
            " 아니\n",
            " 음\n",
            " 음\n",
            " 왜\n",
            " 뭐가 있어요?\n",
            " 힘줄?\n",
            " 힘줄인가?\n",
            " 소의 힘줄이지 뭐 뼈가 있겠어요?\n",
            " 뼈도 있지\n",
            " 그 비아냥거리는 말투도 싫어요\n",
            " 어떻게 살아요 내랑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_end = [(x[\"start\"], x[\"end\"]) for c, x in enumerate(segments)]"
      ],
      "metadata": {
        "id": "t968kCeJACrl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(start_end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-zTF9hHAjPV",
        "outputId": "03e16b30-b165-42fe-d911-1c9f7dda7f14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 7.4), (7.4, 9.040000000000001), (9.040000000000001, 11.040000000000001), (11.040000000000001, 13.040000000000001), (13.040000000000001, 15.040000000000001), (15.040000000000001, 17.04), (17.04, 19.04), (19.04, 19.84), (19.84, 21.84), (21.84, 23.84), (23.84, 25.84), (25.84, 27.84), (28.68, 30.68), (32.68, 34.68)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(start_end))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj4TebAgAnKr",
        "outputId": "f0e9dd9f-863b-4080-81a1-df076a6c2455"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "\n",
        "def segment_wav_file(input_file_path, output_file_path, start_ms, end_ms):\n",
        "    # Open the input WAV file\n",
        "    with wave.open(input_file_path, 'rb') as input_wav:\n",
        "        # Get the sample width (in bytes) and the number of channels\n",
        "        sample_width = input_wav.getsampwidth()\n",
        "        num_channels = input_wav.getnchannels()\n",
        "        # Calculate the start and end positions (in frames)\n",
        "        #start_pos = int(start_ms * input_wav.getframerate() / 1000)\n",
        "        #end_pos = int(end_ms * input_wav.getframerate() / 1000)\n",
        "        start_pos = int(start_ms * input_wav.getframerate() )\n",
        "        end_pos = int(end_ms * input_wav.getframerate())\n",
        "        # Calculate the number of frames to read\n",
        "        num_frames = end_pos - start_pos\n",
        "        # Set the parameters for the output WAV file\n",
        "        output_wav = wave.open(output_file_path, 'wb')\n",
        "        output_wav.setparams((num_channels, sample_width, input_wav.getframerate(), num_frames, input_wav.getcomptype(), input_wav.getcompname()))\n",
        "        # Set the position in the input WAV file\n",
        "        input_wav.setpos(start_pos)\n",
        "        # Read the frames from the input WAV file and write them to the output WAV file\n",
        "        output_wav.writeframes(input_wav.readframes(num_frames))\n",
        "        # Close the output WAV file\n",
        "        output_wav.close()"
      ],
      "metadata": {
        "id": "psjn9AhY_H_c"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segment_wav_file(input_file_path, output_file_path, start_ms, end_ms)"
      ],
      "metadata": {
        "id": "1a6h8_CE_7iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 1\n",
        "for start, end in start_end:\n",
        "  # mill_secs has start and end pair\n",
        "  # segment the WAV file into pieces\n",
        "  segment_wav_file(\"marriage_conversation.wav\", f\"segmented{count}.wav\", start, end)\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "ZlI7i6jV_7f1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import torch\n",
        " # for the new model\n",
        " embedding_model = torch.hub.load('RF5/simple-speaker-embedding', 'convgru_embedder')\n",
        " # for the original model\n",
        " # model = torch.hub.load('RF5/simple-speaker-embedding', 'gru_embedder')\n",
        " embedding_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEX5YO0i_7dP",
        "outputId": "97f0deeb-ba8e-4a0c-d636-d3e6bd9b9ca4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/RF5_simple-speaker-embedding_master\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvGRUEmbedder(\n",
              "  (model): ConvRNNEmbedder(\n",
              "    (conv_encoder): ConvEncoder(\n",
              "      (conv_layers): ModuleList(\n",
              "        (0): Sequential(\n",
              "          (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
              "          (1): Dropout(p=0.0, inplace=False)\n",
              "          (2): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
              "          (3): GELU(approximate='none')\n",
              "        )\n",
              "        (1-4): 4 x Sequential(\n",
              "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "          (1): Dropout(p=0.0, inplace=False)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "        (5-6): 2 x Sequential(\n",
              "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "          (1): Dropout(p=0.0, inplace=False)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rnn): GRU(512, 768, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "    (head): Linear(in_features=1536, out_features=256, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mel = model.melspec_from_file('marriage_conversation.wav')\n",
        "#if you were using the `convgru_embedder`, you can go:\n",
        "import librosa\n",
        "wav1, _ = librosa.load('segmented1.wav', sr=16000)\n",
        "wav1 = torch.from_numpy(wav1).float()\n",
        "\n",
        "wav2, _ = librosa.load('segmented2.wav', sr=16000)\n",
        "wav2 = torch.from_numpy(wav2).float()\n",
        "\n",
        "\n",
        "e = [] # list of vectors of audio files\n",
        "\n",
        "for count in range(len(start_end)):\n",
        "  wav, _ = librosa.load(f'segmented{count + 1}.wav', sr=16000)\n",
        "  wav = torch.from_numpy(wav).float()\n",
        "  element = embedding_model(wav[None])\n",
        "  e.append(element)"
      ],
      "metadata": {
        "id": "0H9r6FE5_7aG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# e1 = embedding_model(wav1[None]) # torch.Size([1, 256])\n",
        "# e2 = embedding_model(wav2[None])"
      ],
      "metadata": {
        "id": "XXeicZfc_7XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULnai_nTGwnA",
        "outputId": "79a7bc8c-7f4a-40a1-fa68-9ab5a828f4d4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(e[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDo417kGwd4",
        "outputId": "75830eb1-b66c-4413-d956-a77927e566ea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "7LhvmjewCwZn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e2 = [data.cpu().detach().numpy().flatten() for data in e] # flattened vectors"
      ],
      "metadata": {
        "id": "uzcMiU7WG-Qu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(e2[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s2nZa2RHX5e",
        "outputId": "7dbf1047-749e-46fc-b7ea-a9607e5b3a5d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine(e2[0], e2[1]))\n",
        "print(cosine(e2[0], e2[2]))\n",
        "print(cosine(e2[0], e2[3]))\n",
        "print(cosine(e2[0], e2[4]))\n",
        "print(cosine(e2[0], e2[5]))\n",
        "print(cosine(e2[0], e2[6]))\n",
        "print(cosine(e2[0], e2[7]))\n",
        "print(cosine(e2[0], e2[8]))\n",
        "print(cosine(e2[0], e2[9]))\n",
        "print(cosine(e2[0], e2[10]))\n",
        "print(cosine(e2[0], e2[11]))\n",
        "print(cosine(e2[0], e2[12]))\n",
        "print(cosine(e2[0], e2[13]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pATsUtvFHg5R",
        "outputId": "6c17cd3d-baae-4f74-c1b6-584dea710bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8749587535858154\n",
            "0.4259982109069824\n",
            "0.8223230689764023\n",
            "1.018939957022667\n",
            "1.0134530663490295\n",
            "1.08206807076931\n",
            "0.5749915242195129\n",
            "0.9546050019562244\n",
            "0.813438892364502\n",
            "1.0255341492593288\n",
            "1.001039493829012\n",
            "0.31542545557022095\n",
            "0.9656992666423321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "metadata": {
        "id": "AVlMlRQ-Hgzk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = AgglomerativeClustering(n_clusters=2).fit(e2)"
      ],
      "metadata": {
        "id": "0eYN5HsHSL6y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clustering.labels_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7OI2FuQSL4P",
        "outputId": "0b96a6c4-e520-4424-bb25-55e1ee9f4647"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 0 0 0 1 0 0 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for count, x in enumerate(segments):\n",
        "  print(f\"speaker {clustering.labels_[count]} :\", x[\"text\"])"
      ],
      "metadata": {
        "id": "inrLwSrNSLzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03aeadb-549e-482a-a5dd-c12a868d8aa0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speaker 1 :  그냥 여보가 말을 좀 가끔씩 아직은 노력 많이 하지만 거칠게 할 때가 있어서\n",
            "speaker 0 :  존댓말 쓰잖아요 그래서\n",
            "speaker 1 :  거칠게 존댓말 하잖아요\n",
            "speaker 0 :  아니\n",
            "speaker 0 :  음\n",
            "speaker 0 :  음\n",
            "speaker 0 :  왜\n",
            "speaker 1 :  뭐가 있어요?\n",
            "speaker 0 :  힘줄?\n",
            "speaker 0 :  힘줄인가?\n",
            "speaker 0 :  소의 힘줄이지 뭐 뼈가 있겠어요?\n",
            "speaker 0 :  뼈도 있지\n",
            "speaker 1 :  그 비아냥거리는 말투도 싫어요\n",
            "speaker 0 :  어떻게 살아요 내랑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hlW8uD6Hgxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}