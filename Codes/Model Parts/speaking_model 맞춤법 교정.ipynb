{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvdc1yFM1mqt"
      },
      "source": [
        "*** Speaker diarization and transcription\n",
        "1. Use Whisper model to get transcription and (start, end) pair\n",
        "2. Segment the audio file into pieces according to (start, end) pair that we got from (1)\n",
        "3. Do speaker embedding\n",
        "4. Use {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgKtiItW1gTZ",
        "outputId": "616632d0-b40a-481e-c011-963350b8164c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U yt-dlp -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9yO36k_3-mN"
      },
      "outputs": [],
      "source": [
        "!wget -O - -q  https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz | xz -qdc| tar -x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW8zSbBO3_vi",
        "outputId": "55a32a49-8a79-4597-e948-91c5091c7695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] Command-line config: ['-xv', '--ffmpeg-location', 'ffmpeg-master-latest-linux64-gpl/bin', '--audio-format', 'wav', '-o', 'marriage_conversation.wav', '--', 'https://youtu.be/H0gH8orEidc']\n",
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out utf-8, error utf-8, screen utf-8\n",
            "[debug] yt-dlp version stable@2023.03.04 [392389b7d] (pip)\n",
            "[debug] Python 3.10.11 (CPython x86_64 64bit) - Linux-5.10.147+-x86_64-with-glibc2.31 (OpenSSL 1.1.1f  31 Mar 2020, glibc 2.31)\n",
            "[debug] exe versions: ffmpeg N-110486-ga59b4ac713-20230505 (setts), ffprobe N-110486-ga59b4ac713-20230505\n",
            "[debug] Optional libraries: Cryptodome-3.17, brotli-1.0.9, certifi-2022.12.07, mutagen-1.46.0, sqlite3-2.6.0, websockets-11.0.2\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Loaded 1786 extractors\n",
            "[youtube] Extracting URL: https://youtu.be/H0gH8orEidc\n",
            "[youtube] H0gH8orEidc: Downloading webpage\n",
            "[youtube] H0gH8orEidc: Downloading android player API JSON\n",
            "[youtube] H0gH8orEidc: Downloading player 50cf60f0\n",
            "[debug] Saving youtube-nsig.50cf60f0 to cache\n",
            "[debug] [youtube] Decrypted nsig Zik62dP6kFE_Z9RaG-B => MKMtT93LZerUXA\n",
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, filesize, fs_approx, tbr, vbr, abr, asr, vext, aext, hasaud, id\n",
            "[info] H0gH8orEidc: Downloading 1 format(s): 251\n",
            "[debug] Invoking dashsegments downloader on \"https://rr5---sn-qxoednee.googlevideo.com/videoplayback?expire=1683317717&ei=dA9VZKCAO_eUsfIP4IWWiA4&ip=35.230.28.197&id=o-AOuNfVW6ygqNSheMfJJoZGkBjPbPaKzX5owZ7PpvYnrx&itag=251&source=youtube&requiressl=yes&mh=Q7&mm=31%2C29&mn=sn-qxoednee%2Csn-qxo7rn7r&ms=au%2Crdu&mv=m&mvi=5&pl=21&ctier=SH&spc=qEK7B5VbspJnkCM0QAQGaY-buUHgW4s&vprv=1&svpuc=1&mime=audio%2Fwebm&gir=yes&clen=553145&dur=36.161&lmt=1671093450673261&mt=1683295764&fvip=4&keepalive=yes&fexp=24007246&c=ANDROID&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cctier%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cgir%2Cclen%2Cdur%2Clmt&sig=AOq0QJ8wRQIgD5qQ0wGq4XgNEQ8Ldpkj5Da3-5qmaIlhe9hCW5acgYQCIQD4XqZTyZhPGEz5P_f1bCjFcVc6aOXbChsE9H3uicR1ZA%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AG3C_xAwRQIgWeDcBoq5iHXswsSHVEkE1UUUBhY8dNDDzXebO47M9d4CIQDdbdGdCTjHVX1TNswLZgJ5GpA6TI14F9t7o62mbCh4ew%3D%3D\"\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: marriage_conversation.webm\n",
            "\u001b[K[download] 100% of  540.18KiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m2.48MiB/s\u001b[0m\n",
            "[debug] ffmpeg command line: ffmpeg-master-latest-linux64-gpl/bin/ffprobe -show_streams file:marriage_conversation.webm\n",
            "[ExtractAudio] Destination: marriage_conversation.wav\n",
            "[debug] ffmpeg command line: ffmpeg-master-latest-linux64-gpl/bin/ffmpeg -y -loglevel repeat+info -i file:marriage_conversation.webm -vn -movflags +faststart file:marriage_conversation.wav\n",
            "Deleting original file marriage_conversation.webm (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "# 부부 대화\n",
        "!yt-dlp -xv --ffmpeg-location ffmpeg-master-latest-linux64-gpl/bin --audio-format wav  -o marriage_conversation.wav -- https://youtu.be/H0gH8orEidc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MXb9xlW3_sM"
      },
      "outputs": [],
      "source": [
        "!pip install pydub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_UzrZYl3_VK",
        "outputId": "92dcab43-437f-4965-b1ac-27b7b248147e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.0+cu118\n",
            "Uninstalling torch-2.0.0+cu118:\n",
            "  Successfully uninstalled torch-2.0.0+cu118\n",
            "Found existing installation: torchvision 0.15.1+cu118\n",
            "Uninstalling torchvision-0.15.1+cu118:\n",
            "  Successfully uninstalled torchvision-0.15.1+cu118\n",
            "Found existing installation: torchaudio 2.0.1+cu118\n",
            "Uninstalling torchaudio-2.0.1+cu118:\n",
            "  Successfully uninstalled torchaudio-2.0.1+cu118\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip uninstall --yes torch torchvision torchaudio \n",
        "! pip3 install torch torchvision torchaudio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9FlID7o4mey"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-deWqc56Y_q",
        "outputId": "f806a09d-50ba-4f64-ad6f-3c1876ae5d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simple-speaker-embedding'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 116 (delta 63), reused 70 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (116/116), 1.22 MiB | 6.47 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/RF5/simple-speaker-embedding.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5jdiW3e-eKr"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import wave\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt58mt-q6JbW",
        "outputId": "13408f6b-c997-4df0-82ec-eb57c962f5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [01:03<00:00, 48.8MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"large-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVp2o5iP7SPS"
      },
      "outputs": [],
      "source": [
        "result = model.transcribe(\"marriage_conversation.wav\")\n",
        "segments = result[\"segments\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaymJz0r_apE",
        "outputId": "a46a42bf-3939-4ebf-f1a5-0f99752af953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.4, 'text': ' 그냥 여보가 말을 좀 가끔씩 아직은 노력 많이 하지만 거칠게 할 때가 있어서', 'tokens': [50364, 11208, 8228, 7062, 1453, 39692, 6796, 10583, 30895, 24317, 22729, 2124, 49388, 8358, 23286, 3675, 45398, 1810, 8981, 7765, 1453, 27937, 50734], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 1, 'seek': 0, 'start': 7.4, 'end': 9.040000000000001, 'text': ' 존댓말 쓰잖아요 그래서', 'tokens': [50734, 22116, 1327, 234, 241, 11023, 17373, 13928, 8844, 50816], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 2, 'seek': 0, 'start': 9.040000000000001, 'end': 11.040000000000001, 'text': ' 거칠게 존댓말 하잖아요', 'tokens': [50816, 3675, 45398, 1810, 22116, 1327, 234, 241, 11023, 3369, 13928, 50916], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 3, 'seek': 0, 'start': 11.040000000000001, 'end': 13.040000000000001, 'text': ' 아니', 'tokens': [50916, 5651, 51016], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 4, 'seek': 0, 'start': 13.040000000000001, 'end': 15.040000000000001, 'text': ' 음', 'tokens': [51016, 220, 5654, 51116], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 5, 'seek': 0, 'start': 15.040000000000001, 'end': 17.04, 'text': ' 음', 'tokens': [51116, 15179, 51216], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 6, 'seek': 0, 'start': 17.04, 'end': 19.04, 'text': ' 왜', 'tokens': [51216, 9883, 51316], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 7, 'seek': 0, 'start': 19.04, 'end': 19.84, 'text': ' 뭐가 있어요?', 'tokens': [51316, 39713, 12654, 30, 51356], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 8, 'seek': 0, 'start': 19.84, 'end': 21.84, 'text': ' 힘줄?', 'tokens': [51356, 30326, 23620, 30, 51456], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 9, 'seek': 0, 'start': 21.84, 'end': 23.84, 'text': ' 힘줄인가?', 'tokens': [51456, 30326, 23620, 41755, 30, 51556], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 10, 'seek': 0, 'start': 23.84, 'end': 25.84, 'text': ' 소의 힘줄이지 뭐 뼈가 있겠어요?', 'tokens': [51556, 10614, 2785, 30326, 23620, 25721, 7034, 531, 120, 230, 1453, 2297, 30826, 30, 51656], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 11, 'seek': 0, 'start': 25.84, 'end': 27.84, 'text': ' 뼈도 있지', 'tokens': [51656, 531, 120, 22616, 37693, 51756], 'temperature': 0.0, 'avg_logprob': -0.4083606680643927, 'compression_ratio': 1.5132275132275133, 'no_speech_prob': 0.2872884273529053}, {'id': 12, 'seek': 2784, 'start': 28.68, 'end': 30.68, 'text': ' 그 비아냥거리는 말투도 싫어요', 'tokens': [50406, 4296, 10079, 23733, 10408, 4261, 7078, 1098, 7058, 169, 48458, 1838, 33649, 4213, 50506], 'temperature': 0.0, 'avg_logprob': -0.3816612492436948, 'compression_ratio': 0.8846153846153846, 'no_speech_prob': 0.22522757947444916}, {'id': 13, 'seek': 2784, 'start': 32.68, 'end': 34.68, 'text': ' 어떻게 살아요 내랑', 'tokens': [50606, 12952, 46978, 1495, 15139, 9143, 50706], 'temperature': 0.0, 'avg_logprob': -0.3816612492436948, 'compression_ratio': 0.8846153846153846, 'no_speech_prob': 0.22522757947444916}]\n"
          ]
        }
      ],
      "source": [
        "print(segments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMRl_bQH-9XQ",
        "outputId": "60db0364-5729-4acd-e146-ad30c4425683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 그냥 여보가 말을 좀 가끔씩 아직은 노력 많이 하지만 거칠게 할 때가 있어서\n",
            " 존댓말 쓰잖아요 그래서\n",
            " 거칠게 존댓말 하잖아요\n",
            " 아니\n",
            " 음\n",
            " 음\n",
            " 왜\n",
            " 뭐가 있어요?\n",
            " 힘줄?\n",
            " 힘줄인가?\n",
            " 소의 힘줄이지 뭐 뼈가 있겠어요?\n",
            " 뼈도 있지\n",
            " 그 비아냥거리는 말투도 싫어요\n",
            " 어떻게 살아요 내랑\n"
          ]
        }
      ],
      "source": [
        "for count, x in enumerate(segments):\n",
        "  response = requests.post('http://164.125.7.61/speller/results', data={'text1': x['text']})\n",
        "  data = response.text.split('data = [', 1)[-1].rsplit('];', 1)[0]\n",
        "  if data[0]=='<':\n",
        "    continue\n",
        "  data = json.loads(data)\n",
        "  for err in data['errInfo']:\n",
        "    var = str(err['candWord'])\n",
        "    a = var.split('|')\n",
        "    x['text'] = x['text'].replace(err['orgStr'],a[0])\n",
        "    print(\"\\n\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t968kCeJACrl"
      },
      "outputs": [],
      "source": [
        "start_end = [(x[\"start\"], x[\"end\"]) for c, x in enumerate(segments)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-zTF9hHAjPV",
        "outputId": "a8624b96-c421-4410-86c0-40136ff1c5a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 7.4), (7.4, 9.040000000000001), (9.040000000000001, 11.040000000000001), (11.040000000000001, 13.040000000000001), (13.040000000000001, 15.040000000000001), (15.040000000000001, 17.04), (17.04, 19.04), (19.04, 19.84), (19.84, 21.84), (21.84, 23.84), (23.84, 25.84), (25.84, 27.84), (28.68, 30.68), (32.68, 34.68)]\n"
          ]
        }
      ],
      "source": [
        "print(start_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj4TebAgAnKr",
        "outputId": "90c02b72-c274-4bac-de07-f113b6b33c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "print(len(start_end))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psjn9AhY_H_c"
      },
      "outputs": [],
      "source": [
        "import wave\n",
        "\n",
        "def segment_wav_file(input_file_path, output_file_path, start_ms, end_ms):\n",
        "    # Open the input WAV file\n",
        "    with wave.open(input_file_path, 'rb') as input_wav:\n",
        "        # Get the sample width (in bytes) and the number of channels\n",
        "        sample_width = input_wav.getsampwidth()\n",
        "        num_channels = input_wav.getnchannels()\n",
        "        # Calculate the start and end positions (in frames)\n",
        "        #start_pos = int(start_ms * input_wav.getframerate() / 1000)\n",
        "        #end_pos = int(end_ms * input_wav.getframerate() / 1000)\n",
        "        start_pos = int(start_ms * input_wav.getframerate() )\n",
        "        end_pos = int(end_ms * input_wav.getframerate())\n",
        "        # Calculate the number of frames to read\n",
        "        num_frames = end_pos - start_pos\n",
        "        # Set the parameters for the output WAV file\n",
        "        output_wav = wave.open(output_file_path, 'wb')\n",
        "        output_wav.setparams((num_channels, sample_width, input_wav.getframerate(), num_frames, input_wav.getcomptype(), input_wav.getcompname()))\n",
        "        # Set the position in the input WAV file\n",
        "        input_wav.setpos(start_pos)\n",
        "        # Read the frames from the input WAV file and write them to the output WAV file\n",
        "        output_wav.writeframes(input_wav.readframes(num_frames))\n",
        "        # Close the output WAV file\n",
        "        output_wav.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a6h8_CE_7iE"
      },
      "outputs": [],
      "source": [
        "#segment_wav_file(input_file_path, output_file_path, start_ms, end_ms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlI7i6jV_7f1"
      },
      "outputs": [],
      "source": [
        "count = 1\n",
        "for start, end in start_end:\n",
        "  # mill_secs has start and end pair\n",
        "  # segment the WAV file into pieces\n",
        "  segment_wav_file(\"marriage_conversation.wav\", f\"segmented{count}.wav\", start, end)\n",
        "  count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEX5YO0i_7dP",
        "outputId": "17720e18-a06a-43ce-b65a-25beefa73c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/RF5/simple-speaker-embedding/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/RF5/simple-speaker-embedding/releases/download/v1.0/convgru_ckpt_00700000_strip.pt\" to /root/.cache/torch/hub/checkpoints/convgru_ckpt_00700000_strip.pt\n",
            "100%|██████████| 121M/121M [00:01<00:00, 73.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvGRUEmbedder(\n",
              "  (model): ConvRNNEmbedder(\n",
              "    (conv_encoder): ConvEncoder(\n",
              "      (conv_layers): ModuleList(\n",
              "        (0): Sequential(\n",
              "          (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
              "          (1): Dropout(p=0.0, inplace=False)\n",
              "          (2): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
              "          (3): GELU(approximate='none')\n",
              "        )\n",
              "        (1-4): 4 x Sequential(\n",
              "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "          (1): Dropout(p=0.0, inplace=False)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "        (5-6): 2 x Sequential(\n",
              "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "          (1): Dropout(p=0.0, inplace=False)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rnn): GRU(512, 768, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "    (head): Linear(in_features=1536, out_features=256, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        " import torch\n",
        " # for the new model\n",
        " embedding_model = torch.hub.load('RF5/simple-speaker-embedding', 'convgru_embedder')\n",
        " # for the original model\n",
        " # model = torch.hub.load('RF5/simple-speaker-embedding', 'gru_embedder')\n",
        " embedding_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H9r6FE5_7aG"
      },
      "outputs": [],
      "source": [
        "#mel = model.melspec_from_file('marriage_conversation.wav')\n",
        "#if you were using the `convgru_embedder`, you can go:\n",
        "import librosa\n",
        "wav1, _ = librosa.load('segmented1.wav', sr=16000)\n",
        "wav1 = torch.from_numpy(wav1).float()\n",
        "\n",
        "wav2, _ = librosa.load('segmented2.wav', sr=16000)\n",
        "wav2 = torch.from_numpy(wav2).float()\n",
        "\n",
        "\n",
        "e = [] # list of vectors of audio files\n",
        "\n",
        "for count in range(len(start_end)):\n",
        "  wav, _ = librosa.load(f'segmented{count + 1}.wav', sr=16000)\n",
        "  wav = torch.from_numpy(wav).float()\n",
        "  element = embedding_model(wav[None])\n",
        "  e.append(element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXeicZfc_7XE"
      },
      "outputs": [],
      "source": [
        "# e1 = embedding_model(wav1[None]) # torch.Size([1, 256])\n",
        "# e2 = embedding_model(wav2[None])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULnai_nTGwnA",
        "outputId": "0dfb8822-615c-4ff8-b577-f2a28f057758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "print(len(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDo417kGwd4",
        "outputId": "8ee8e1e3-e937-4847-f416-56cd6663a671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256])\n"
          ]
        }
      ],
      "source": [
        "print(e[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LhvmjewCwZn"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzcMiU7WG-Qu"
      },
      "outputs": [],
      "source": [
        "e2 = [data.cpu().detach().numpy().flatten() for data in e] # flattened vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s2nZa2RHX5e",
        "outputId": "6c7e4b79-c488-4e6a-96bb-1a7ae753ea95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256,)\n"
          ]
        }
      ],
      "source": [
        "print(e2[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pATsUtvFHg5R",
        "outputId": "8d130abe-263c-4142-f91d-16c6b30dff9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8749587833881378\n",
            "0.4259982109069824\n",
            "0.8223231732845306\n",
            "1.0189399775117636\n",
            "1.0134530067443848\n",
            "1.0820680558681488\n",
            "0.5749915540218353\n",
            "0.9546049758791924\n",
            "0.8134388476610184\n",
            "1.0255340673029423\n",
            "1.001039482653141\n",
            "0.3154253363609314\n",
            "0.965699315071106\n"
          ]
        }
      ],
      "source": [
        "print(cosine(e2[0], e2[1]))\n",
        "print(cosine(e2[0], e2[2]))\n",
        "print(cosine(e2[0], e2[3]))\n",
        "print(cosine(e2[0], e2[4]))\n",
        "print(cosine(e2[0], e2[5]))\n",
        "print(cosine(e2[0], e2[6]))\n",
        "print(cosine(e2[0], e2[7]))\n",
        "print(cosine(e2[0], e2[8]))\n",
        "print(cosine(e2[0], e2[9]))\n",
        "print(cosine(e2[0], e2[10]))\n",
        "print(cosine(e2[0], e2[11]))\n",
        "print(cosine(e2[0], e2[12]))\n",
        "print(cosine(e2[0], e2[13]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVlMlRQ-Hgzk"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eYN5HsHSL6y"
      },
      "outputs": [],
      "source": [
        "clustering = AgglomerativeClustering(n_clusters=2).fit(e2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7OI2FuQSL4P",
        "outputId": "d983f0fe-8db3-46a2-c538-60c317fdca18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 0 0 0 1 0 0 0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "print(clustering.labels_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inrLwSrNSLzn",
        "outputId": "ee77a7df-f9d2-4bb8-c4f4-5cfbe0c30b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speaker 1 :  그냥 여보가 말을 좀 가끔씩 아직은 노력 많이 하지만 거칠게 할 때가 있어서\n",
            "speaker 0 :  존댓말 쓰잖아요 그래서\n",
            "speaker 1 :  거칠게 존댓말 하잖아요\n",
            "speaker 0 :  아니\n",
            "speaker 0 :  음\n",
            "speaker 0 :  음\n",
            "speaker 0 :  왜\n",
            "speaker 1 :  뭐가 있어요?\n",
            "speaker 0 :  힘줄?\n",
            "speaker 0 :  힘줄인가?\n",
            "speaker 0 :  소의 힘줄이지 뭐 뼈가 있겠어요?\n",
            "speaker 0 :  뼈도 있지\n",
            "speaker 1 :  그 비아냥거리는 말투도 싫어요\n",
            "speaker 0 :  어떻게 살아요 내랑\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "for count, x in enumerate(segments):\n",
        "  print(f\"speaker {clustering.labels_[count]} :\", x[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hlW8uD6Hgxw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}