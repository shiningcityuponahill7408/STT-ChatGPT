{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD64MlYruR0l",
        "outputId": "c3833446-56e5-4ca9-b631-bf021ca79bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvS-qLW4vM20",
        "outputId": "4c7f05ee-25f4-4654-b897-1b509771b2a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.433s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U yt-dlp -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYq2DZ21vQAb",
        "outputId": "14abfe6d-5e84-4f6f-e075-71a20e5a0d3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O - -q  https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz | xz -qdc| tar -x"
      ],
      "metadata": {
        "id": "CuuvBC9RvR3c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub -q"
      ],
      "metadata": {
        "id": "5EImF6ZUvXsL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyannote.audio==2.1.1 -q"
      ],
      "metadata": {
        "id": "ziaAsvLkvY4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall --yes torch torchvision torchaudio \n",
        "! pip3 install torch torchvision torchaudio --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXPkPnhBvfTD",
        "outputId": "cb3a814e-e1dc-41d4-adbc-751144f07298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.13.1\n",
            "Uninstalling torch-1.13.1:\n",
            "  Successfully uninstalled torch-1.13.1\n",
            "Found existing installation: torchvision 0.15.1+cu118\n",
            "Uninstalling torchvision-0.15.1+cu118:\n",
            "  Successfully uninstalled torchvision-0.15.1+cu118\n",
            "Found existing installation: torchaudio 0.13.1\n",
            "Uninstalling torchaudio-0.13.1:\n",
            "  Successfully uninstalled torchaudio-0.13.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyannote-audio 2.1.1 requires torchaudio<1.0,>=0.10, but you have torchaudio 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git > /dev/null"
      ],
      "metadata": {
        "id": "klcGyyKRvlRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/fcakyon/pywhisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPknmd2gMtF-",
        "outputId": "65557520-1c59-4fa3-ff90-3e5caefbd604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pywhisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile stream.py\n",
        "import streamlit as st\n",
        "import get_speakers as gs\n",
        "import transcribe as t\n",
        "\n",
        "# visual components\n",
        "st.title(\"Hi! We recommend a better conversation for you\")\n",
        "\n",
        "# get an audio file; wav and mp3 are allowed to be uploaded\n",
        "audiofile = st.file_uploader(\"Upload an audio file! You can upload .wav or .mp3\", type = [\"wav\", \"mp3\"] )\n",
        "\n",
        "if audiofile is not None:\n",
        "\n",
        "    # when an audio file is given, show the name of it\n",
        "    st.write(f\"we got \\\"{audiofile.name}\\\" file from you\")\n",
        "\n",
        "    num_speakers = gs.get_num_speakers(audiofile)\n",
        "    # if num_speakers <= 1:\n",
        "    #     st.write(f\"we found {num_speakers} person in your audio file!\")\n",
        "\n",
        "    # else:\n",
        "    #     st.write(f\"we found {num_speakers} people in your audio file!\")\n",
        "\n",
        "    T = t.Transcribe(audiofile, num_speakers)\n",
        "    result = T.get_results()\n",
        "    st.write(result)\n",
        "\n",
        "\n",
        "# or get a YouTube link\n",
        "url = st.text_input(\"Or copy and paste a YouTube link!\")\n",
        "\n",
        "if len(url) != 0:\n",
        "    st.write(f\"we got the following link: {url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh-74MZvvn87",
        "outputId": "0bdec336-a469-4268-cc98-3828b98e1410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting stream.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_speakers.py\n",
        "'''\n",
        "add 2 seconds silence to the existing conversation.wav\n",
        "this makes a better diarization\n",
        "'''\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(\"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\")\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pyannote.audio import Pipeline\n",
        "\n",
        "# authorization key should not be exposed\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=\"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\")\n",
        "\n",
        "\n",
        "def get_num_speakers(original_audio):\n",
        "    '''\n",
        "    given an audio file,\n",
        "    return the number of speakers in an audio file: original_audio\n",
        "    '''\n",
        "\n",
        "    t1 = 0 * 1000 # Works in milliseconds\n",
        "    t2 = 10 * 60 * 1000 # t1:t2 is total 10mins\n",
        "\n",
        "    newAudio = AudioSegment.from_wav(original_audio)\n",
        "    a = newAudio[t1:t2]\n",
        "    a.export(\"conversation.wav\", format=\"wav\") \n",
        "\n",
        "    audio = AudioSegment.from_wav(\"conversation.wav\")\n",
        "    spacermilli = 2000\n",
        "    spacer = AudioSegment.silent(duration=spacermilli)\n",
        "    audio = spacer.append(audio, crossfade=0)\n",
        "\n",
        "    audio.export('audio.wav', format='wav')\n",
        "\n",
        "    # 4. apply pretrained pipeline\n",
        "    diarization = pipeline(\"audio.wav\")\n",
        "\n",
        "    how_many = set()\n",
        "    # 5. print the result\n",
        "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "        print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
        "        how_many.add(int(speaker[-2:]))\n",
        "\n",
        "    # the length of how_many is the total number of speakers in an audio file\n",
        "    #print(len(how_many))\n",
        "\n",
        "    return len(how_many)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpz6N93HvrDM",
        "outputId": "d89e68c8-5b2a-4e30-efaf-3ad29d15da35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_speakers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile transcribe.py\n",
        "\n",
        "from get_speakers import get_num_speakers\n",
        "import whisper\n",
        "import datetime\n",
        "\n",
        "import subprocess\n",
        "\n",
        "import torch\n",
        "import pyannote.audio\n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
        "embedding_model = PretrainedSpeakerEmbedding( \n",
        "    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    device=torch.device(\"cuda\"))\n",
        "\n",
        "from pyannote.audio import Audio\n",
        "from pyannote.core import Segment\n",
        "\n",
        "import wave\n",
        "import contextlib\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "\n",
        "# I added this codes\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "import pywhisper\n",
        "\n",
        "\n",
        "'''\n",
        "여기에서는 음성파일을 받아서\n",
        "get_speakers.py 로 부터는 음성파일 속에 몇명이 있는지를 받아서\n",
        "대화 전사를 하는 파일\n",
        "'''\n",
        "\n",
        "class Transcribe():\n",
        "    '''\n",
        "    this class is for getting audio and number of speakers from stream.py\n",
        "    given those, transcribe the audio\n",
        "    '''\n",
        "    def __init__(self, audio, num_speakers):\n",
        "        self.audio = audio\n",
        "        self.num_speakers = num_speakers\n",
        "        self.path = audio.name\n",
        "        self.language = \"any\"\n",
        "        self.model_size = 'large'\n",
        "\n",
        "    # available models = ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large']\n",
        "    def load_whisper_model(self):\n",
        "      model = whisper.load_model(self.model_size)\n",
        "      return model\n",
        "\n",
        "    # execute the trascribtion\n",
        "    def execute(self):\n",
        "        model = self.load_whisper_model()\n",
        "        result = model.transcribe(\"conversation.wav\") ########self.path\n",
        "        segments = result[\"segments\"]\n",
        "        return segments\n",
        "    \n",
        "    def clustering(self):\n",
        "        with contextlib.closing(wave.open(\"conversation.wav\",'r')) as f: #self.path\n",
        "          frames = f.getnframes()\n",
        "          rate = f.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "        audio = Audio()\n",
        "        return audio\n",
        "\n",
        "    def segment_embedding(self, segment):\n",
        "      audio = self.clustering()\n",
        "      start = segment[\"start\"]\n",
        "      # Whisper overshoots the end timestamp in the last segment\n",
        "      #end = min(duration, segment[\"end\"])\n",
        "      with contextlib.closing(wave.open(\"conversation.wav\",'r')) as f: #self.path\n",
        "          frames = f.getnframes()\n",
        "          rate = f.getframerate()\n",
        "      duration = frames / float(rate)\n",
        "      end = min(duration, segment[\"end\"])\n",
        "      clip = Segment(start, end)\n",
        "      waveform, sample_rate = audio.crop(self.path, clip)\n",
        "      \n",
        "      return embedding_model(waveform[None])\n",
        "    \n",
        "    def get_results(self):\n",
        "      segments = self.execute()\n",
        "      embeddings = np.zeros(shape=(len(segments), 192))\n",
        "      for i, segment in enumerate(segments):\n",
        "          embeddings[i] = self.segment_embedding(segment)\n",
        "\n",
        "      embeddings = np.nan_to_num(embeddings)\n",
        "\n",
        "      clustering = AgglomerativeClustering(self.num_speakers).fit(embeddings)\n",
        "      labels = clustering.labels_\n",
        "      for i in range(len(segments)):\n",
        "          segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)\n",
        "\n",
        "      result = [ seg[\"speaker\"] + \": \" + seg[\"text\"] for c, seg in enumerate(segments)]\n",
        "      return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RArS_fYTvtZ8",
        "outputId": "e9c568d3-65b0-4c5f-d1b1-c2912c9522b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting transcribe.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall ffmpeg --yes\n",
        "!pip uninstall ffmpeg-python --yes\n",
        "\n",
        "!pip install ffmpeg-python -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YoreSQpLPLG",
        "outputId": "99fbba3c-288d-45de-a902-014fa9a6d645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping ffmpeg as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: ffmpeg-python 0.2.0\n",
            "Uninstalling ffmpeg-python-0.2.0:\n",
            "  Successfully uninstalled ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/stream.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "1tza1olKvvDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuLApXfyvwRK",
        "outputId": "b1edff1d-7a2f-4469-bf9e-8223291843d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.801s\n",
            "your url is: https://curly-bushes-beg-35-224-100-215.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-hL1CrMbNWZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}